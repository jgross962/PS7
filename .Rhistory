#ratings.data = as.data.frame(ratings.data)
rownames(ratings.data) = ticker.symbols
avg.rating = mean(ratings.data[,1:5])
avg.rating
avg.rating = apply(ratings.data, 2, mean)
avg.rating
avg.rating = apply(ratings.data, 1, mean)
avg.rating
avg.rating = apply(ratings.data, 1, mean)
###### Split to Traingin Testings
setwd("C:/Users/jgros/Documents/GitHub/515Project/")
training.index = 1:83
price.training = price.data[,training.index]
price.testing = price.data[,-training.index]
returns.training = returns.data[,training.index]
returns.testing = returns.data[,-training.index]
results
# set directory
setwd("C:/Users/jgros/Documents/GitHub/515Project/data")
# Get Files Names
temp = list.files(pattern="*.csv")
#Get list of just ticker Symbols
getTickers = function(x){
return(
substring(x,1,nchar(x)-4)
)
}
ticker.symbols = sapply(temp, getTickers)
price.data = matrix(nrow = 30, ncol = 124)
# Import Price Data
for (i in 1:length(temp)){
price.data[i,] = read.csv(temp[i])$Adj.Close
}
rownames(price.data) = ticker.symbols
######## Bring in Ratings
# set directory for ratings
setwd("C:/Users/jgros/Documents/GitHub/515Project/Ratings")
# Get File Names
tempRat = list.files(pattern="*.xlsx")
# Import Ratings Data
ratings.data = matrix(nrow = 30, ncol = 5)
for (i in 1:length(tempRat)){
ratings.data[i,] = read_excel(tempRat[i])[[5]]
}
#ratings.data = as.data.frame(ratings.data)
rownames(ratings.data) = ticker.symbols
returns.data = data.matrix()
returns.data = matrix(nrow = 30, ncol = 123)
for (i in 1:123){
returns.data[,i] = (price.data[,i+1]-price.data[,i])/price.data[,i] # In decimal Format
}
avg.rating = apply(ratings.data, 1, mean)
avg.rating
normalizedAvgRating =avg.rating/5
normalizedAvgRating
scaledAvgRating =avg.rating/5
###### Split to Training Testing Data
setwd("C:/Users/jgros/Documents/GitHub/515Project/")
training.index = 1:83
price.training = price.data[,training.index]
price.testing = price.data[,-training.index]
returns.training = returns.data[,training.index]
returns.testing = returns.data[,-training.index]
##Logistic Function
logist= function(x){
ff= 1/(1 + exp(-x))
return(ff)
}
?bayesglm
returns.data
########## Bring in Market Data
setwd("C:/Users/jgros/Documents/GitHub/515Project/")
list.files()
read.csv("NASDAQ.csv")$Return
market.return = read.csv("NASDAQ.csv")$Return[2:124]
#### Beat Market?
asset.market = returns.data-market.return
returns.data[1,]
market.return
asset.market
asset.market[1,]
returns.data[2,]
asset.market[2,]
market.return
class(returns.data)
asset.market= matrix(nrow = 30, ncol = 124)
#### Beat Market?
for (i in 1:30){
asset.market[i,] = returns.data[i,]-market.return
}
length(returns.data[1,])
length(market.return)
returns.data[i,]-market.return
asset.market= matrix(nrow = 30, ncol = 123)
#### Beat Market?
for (i in 1:30){
asset.market[i,] = returns.data[i,]-market.return
}
beat.market = adj.return>0
#### Beat Market?
adj.return= matrix(nrow = 30, ncol = 123)
for (i in 1:30){
adj.return[i,] = returns.data[i,]-market.return
}
beat.market = adj.return>0
beat.market
beat.market = as.numeric(adj.return>0)
beat.market = (adj.return>0)
beat.market[which(beat.market==0)] = -1
beat.market
cum.beat.market = apply(beat.market,2,sum)
cum.beat.market
cum.beat.market = apply(beat.market,1,sum)
cum.beat.market
cum.beat.market = cum.beat.market>0
cum.beat.market
?sd
sd.ratings = apply(ratings.data,1,sd)
?rbeta
## Treat cum.beat.market as an observation from a bernoulli distribution
## Beta Prior (Since Conjguate Prior For Bernoulli/Binomial)
estBetaParams <- function(mu, var) {
alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta <- alpha * (1 / mu - 1)
return(params = list(alpha = alpha, beta = beta))
}
beta.params = matrix(nrow = 30, ncol = 2)
for (i in 1:30){
beta.params[i,] = estBetaParams(scaledAvgRating[i],sd.ratings[i])
}
i = 2
estBetaParams(scaledAvgRating[i],sd.ratings[i])
beta.params[i] = estBetaParams(scaledAvgRating[i],sd.ratings[i])
j = estBetaParams(scaledAvgRating[i],sd.ratings[i])
length(j)
dim(j)
class(j)
return(c(alpha, beta))
## Treat cum.beat.market as an observation from a bernoulli distribution
## Beta Prior (Since Conjguate Prior For Bernoulli/Binomial)
estBetaParams <- function(mu, var) {
alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta <- alpha * (1 / mu - 1)
return(c(alpha, beta))
}
row.names(params) = c("Alpha","Beta")
## Treat cum.beat.market as an observation from a bernoulli distribution
## Beta Prior (Since Conjguate Prior For Bernoulli/Binomial)
estBetaParams <- function(mu, var) {
alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta <- alpha * (1 / mu - 1)
params = c(alpha,beta)
row.names(params) = c("Alpha","Beta")
return(c(alpha, beta))
}
beta.params = matrix(nrow = 30, ncol = 2)
for (i in 1:30){
beta.params[i,] = estBetaParams(scaledAvgRating[i],sd.ratings[i])
}
## Treat cum.beat.market as an observation from a bernoulli distribution
## Beta Prior (Since Conjguate Prior For Bernoulli/Binomial)
estBetaParams <- function(mu, var) {
alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta <- alpha * (1 / mu - 1)
params = c(alpha,beta)
rownames(params) = c("Alpha","Beta")
return(c(alpha, beta))
}
beta.params = matrix(nrow = 30, ncol = 2)
for (i in 1:30){
beta.params[i,] = estBetaParams(scaledAvgRating[i],sd.ratings[i])
}
a = c(1,2)
names(a) = c("a","b")
a
## Treat cum.beat.market as an observation from a bernoulli distribution
## Beta Prior (Since Conjguate Prior For Bernoulli/Binomial)
estBetaParams <- function(mu, var) {
alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta <- alpha * (1 / mu - 1)
params = c(alpha,beta)
names(params) = c("Alpha","Beta")
return(c(alpha, beta))
}
beta.params = matrix(nrow = 30, ncol = 2)
for (i in 1:30){
beta.params[i,] = estBetaParams(scaledAvgRating[i],sd.ratings[i])
}
beta.paraa
beta.params
## Treat cum.beat.market as an observation from a bernoulli distribution
## Beta Prior (Since Conjguate Prior For Bernoulli/Binomial)
estBetaParams <- function(mu, var) {
alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta <- alpha * (1 / mu - 1)
params = c(alpha,beta)
return(c(alpha, beta))
}
beta.params = matrix(nrow = 30, ncol = 2)
for (i in 1:30){
beta.params[i,] = estBetaParams(scaledAvgRating[i],sd.ratings[i])
}
colnames(beta.params = c("alpha","beta"))
colnames(beta.params) = c("alpha","beta"))
beta.params
colnames(beta.params) = c("alpha","beta"))
colnames(beta.params) = c("alpha","beta")
beta.params
simple.cum.beat.market
simple.cum.beat.market = cum.beat.market>0
simple.cum.beat.market
sum(simple.cum.beat.market)
? std.error()
load("~/GitHub/Project/CVresultsApril15.RData")
preds.in.order
RMSEforModel = function(x,y, test.indexes = sample(length(y),as.integer(length(y)/10))){
# NOTE: THIS IS NOT DOING CROSS-VALIDATION right now (for most models)
#test.indexes = sample(1074,107)
x.train = x[-test.indexes,]
x.test = x[test.indexes,]
y.train = y[-test.indexes]
y.test = y[test.indexes]
library(glmnet)
##Now predict them
logist<- function(x){
ff<- 1/(1 + exp(-x))
return(ff)
}
##### Take out this Cross-Validation -- just do CV onces for everything to make run faster
# Lasso
fit1<- cv.glmnet(x = x.train, y = y.train, alpha=1, family='binomial', type='mse')
best.lambda = fit1$lambda.min
fit1.predict = predict(fit1, s= best.lambda, newx = x.test)
fit1.logistPred = logist(fit1.predict)
fit1.logistPred.RMSE = sqrt(mean((fit1.logistPred-y.test)^2))
# Elastic Net, Alpha = .5
fit2<- cv.glmnet(y = y.train, x= x.train, alpha=0.5, family='binomial', type='mse')
best.lambda = fit2$lambda.min
fit2.predict = predict(fit2, s= best.lambda, newx = x.test)
fit2.logistPred = logist(fit2.predict)
fit2.logistPred.RMSE = sqrt(mean((fit2.logistPred-y.test)^2))
# Elastic Net, Alpha = .25
fit3<- cv.glmnet(y = y.train, x= x.train, alpha=0.25, family='binomial', type='mse')
best.lambda = fit3$lambda.min
fit3.predict = predict(fit3, s= best.lambda, newx = x.test)
fit3.logistPred = logist(fit3.predict)
fit3.logistPred.RMSE = sqrt(mean((fit3.logistPred-y.test)^2))
# Fit4 not published in paper -- so not doing it
#fit4<- cv.glmnet(y = Y, x= Xfull, alpha=0, family='binomial', type='mse')
## Skipping FindIt since documentation changed (per)
# Bayesian GLM -- Revisit -- probably not working right
library(arm)
fit6<- bayesglm(y.train~x.train-1, family=binomial(link=logit))
fit6.predict = logist(x.test%*%fit6$coefficients)
fit6.logistPred.RMSE = sqrt(mean((fit6.predict-y.test)^2))
# Fit 7 = Boosted Trees is not published ### SKipping
# Fit 8 = BART
library(BayesTree)
fit8<- bart(x.train=x.train, y.train=factor(y.train), x.test=x.test, ndpost=1000, nskip=500, usequants=T)
fit8.pred<- pnorm(apply(fit8$yhat.test, 2, mean))
fit8.rmse = sqrt(mean((fit8.pred-y.test)^2))
# Fit 9  = RandomForest
library(randomForest)
fit9<- randomForest(y = factor(y.train), x = x.train)
X.test.forest = x.test
`colnames<-`(X.test.forest,colnames(x.train))
fit9.pred.raw = predict(fit9,newdata = X.test.forest,type = "prob" )
fit9.pred = fit9.pred.raw[,2]
fit9.rmse = sqrt(mean((fit9.pred-y.test)^2))
# Fit 10 = Skipped in Paper and SLF_round2 code
# Fit 11 = KRLS
library(KRLS)
fit11<- krls(X = x.train[,-1], y = y.train, derivative=F)
fit11.predict = predict(fit11,newdata = x.test[,-1])$fit
fit11.rmse = sqrt(mean((fit11.predict-y.test)^2))
# Fit 12 = SVM-SMO
library(rJava)
.jinit(parameters="-Xmx4g")
library(RWeka)
subset.index = (1:length(y))[-test.indexes]
fit12 <- SMO(y ~ ., data = data.frame(y=factor(y),x), control = Weka_control(M = TRUE ) , subset = subset.index)
fit12.predict =predict(fit12, newdata= data.frame(x[test.indexes,]), type="probability" )[,2]
fit12.RMSE = sqrt(mean((fit12.predict-y.test)^2))
# Fit 13 = Simple Mean
fit13.predict = mean(y.train)
fit13.RSME= sqrt(mean((fit13.predict-y.test)^2))
# W/O Fit12 (Req Java)
# Preds.All = cbind(fit1.logistPred,fit2.logistPred,fit3.logistPred,fit6.predict,fit8.pred,fit9.pred,fit11.predict,  fit13.predict)#fit12
#models = rbind("Lasso", "Elastic Net (a = .5)","Elastic Net (a = .25)", "Bayesian GLM", "BART", "Random Forest", "KRLS" , "Simple Average")#"SVM_SMO"
# W/ Fit 12
Preds.All = cbind(fit1.logistPred,fit2.logistPred,fit3.logistPred,fit6.predict,fit8.pred,fit9.pred,fit11.predict, fit12.predict, fit13.predict)
models = rbind("Lasso", "Elastic Net (a = .5)","Elastic Net (a = .25)", "Bayesian GLM", "BART", "Random Forest", "KRLS" ,"SVM_SMO", "Simple Average")
#RMSE.all = rbind(fit1.logistPred.RMSE,fit2.logistPred.RMSE,fit3.logistPred.RMSE,fit6.logistPred.RMSE,fit8.rmse,fit9.rmse,fit11.rmse,fit12.RMSE, fit13.RSME)
colnames(Preds.All) = models
#return(data.frame(RMSE.all))
return(Preds.All)
}
setwd("C:/Users/jgros/documents/GitHub/Project/")
load("Het_Experiment.Rdata")
dem<- ifelse(svdat$pid3l=='Dem', 1, 0)  #line 366-369 of rep code
dem[which(is.na(dem))]<- 0
rep<- ifelse(svdat$pid3l=='Rep', 1, 0)
rep[which(is.na(rep))]<- 0
cons<- ifelse(svdat$ideo3<3, 1, 0) #line 230-231 of rep code
lib<- ifelse(svdat$ideo3==4|svdat$ideo3==5, 1, 0)
lib[which(is.na(lib))]<- 0 #line 370-371 of rep code
cons[which(is.na(cons))]<- 0
############ Defining treats
type.mat<- matrix(0, nrow = 1074, ncol=7)
colnames(type.mat)<- sort(unique(as.character(svdat$cond.type)))
for(z in 1:nrow(type.mat)){
type.mat[z,which(colnames(type.mat)==svdat$cond.type[z])]<- 1
}
type.mat.final<- type.mat[,-1]
types<- sort(unique(as.character(svdat$cond.type)))
type.num<- match(svdat$cond.type, types)
number<- c('control', '$20 million', '$50 thousand')
amount.num<- match(svdat$cond.money, number)
request<- c('control', 'requested', 'secured', 'will request')
stage.num<- match(svdat$cond.stage, request)
party<- c('control', 'a Republican', 'a Democrat')
party.num<- match(svdat$cond.party, party)
along<- c('control', 'alone', 'w/ Rep', 'w/ Dem')
along.num<- match(svdat$cond.alongWith, along)
num.mat<- matrix(0, nrow=1074, ncol=3)
colnames(num.mat)<- number
for(z in 1:nrow(num.mat)){
num.mat[z,which(colnames(num.mat)==svdat$cond.money[z])]<- 1
}
num.mat.final<- num.mat[,-1]
stage.mat<- matrix(0, nrow=1074, ncol=4)
colnames(stage.mat)<- request
for(z in 1:nrow(stage.mat)){
stage.mat[z,which(colnames(stage.mat)==svdat$cond.stage[z])]<- 1
}
stage.mat.final<- stage.mat[,-1]
party.mat<- matrix(0, nrow=1074, ncol=3)
colnames(party.mat)<- party
for(z in 1:nrow(party.mat)){
party.mat[z, which(colnames(party.mat)==svdat$cond.party[z])]<- 1
}
party.mat.final<- party.mat[,-1]
along.mat<- matrix(0, nrow=1074, ncol=4)
colnames(along.mat)<- 	along
for(z in 1:nrow(along.mat)){
along.mat[z,which(colnames(along.mat)==svdat$cond.alongWith[z])]<- 1
}
along.mat.final<- along.mat[,-1]
treats<- cbind(type.mat.final, num.mat.final[,1], stage.mat.final[,1:2],party.mat.final[,1],
along.mat.final[,1:2], type.mat.final[,1:5]*num.mat.final[,1], type.mat.final[,1:5]*stage.mat.final[,1],
type.mat.final[,1:5]*stage.mat.final[,2], type.mat.final[,1:5]*party.mat.final[,1], type.mat.final[,1:5]*along.mat.final[,1],
type.mat.final[,1:5]*along.mat.final[,2], num.mat.final[,1]*stage.mat.final[,1], num.mat.final[,1]*stage.mat.final[,2],
num.mat.final[,1]*party.mat.final[,1], num.mat.final[,1]*along.mat.final[,1], num.mat.final[,1]*along.mat.final[,2],
stage.mat.final[,1:2]*party.mat.final[,1], stage.mat.final[,1:2]*along.mat.final[,1],
stage.mat.final[,1:2]*along.mat.final[,2], party.mat.final[,1]*along.mat.final[,1], party.mat.final[,1]*along.mat.final[,2] )
treat<- treats #line 448 of rep code
### Defining the X variable
covs<- cbind(dem, rep, lib, cons) #line 373 of rep code
X <- covs #line 432 of repcode
Xfull <- model.matrix(~X*treat)
## line 391 of rep code
#Defining the Y variable
#line 432 of rep code
Y<- approve_bi<- ifelse(svdat$approval<3, 1, 0) #line 292 of rep code
# # One Query
df<-RMSEforModel(Xfull,Y)
df
regress.func <- function(Y, preds.var){
# need to smartly figure out which columns are not NA
orgcols <- length(preds.var[1,])
notNA <- which(!is.na(preds.var[1,]))
predX <- preds.var[,notNA ]
library(quadprog)
d.mat <- solve(chol(t(predX)%*%predX))
a.mat <- cbind(rep(1, ncol(predX)), diag(ncol(predX)))
b.vec <- c(1, rep(0, ncol(predX)))
d.vec <- t(Y) %*% predX
out<- solve.QP(Dmat = d.mat, factorized =TRUE, dvec = d.vec, Amat = a.mat, bvec = b.vec, meq = 1)
coefs <- rep(NA, orgcols)
notDel <- c(1:orgcols)[notNA]#[notCor]
coefs[notDel] <- out$solution
return(coefs)
}
Y.boostrap = numeric(1074,500)
Y.boostrap = matrix(nrow = 1074, ncol = 500)
Y.boostrap
#### Get Indexes
set.seed(10)
seednum = sample(10000,num.boostraps)
########################### Run Bootstrapping #################################
num.boostraps = 500
#### Get Indexes
set.seed(10)
seednum = sample(10000,num.boostraps)
Y.boostrap = numeric(1074,500)
for (i in 1:num.boostraps){
set.seed(seednum[i])
bootstramp.sample.indexes = sample(1074,1074,replace = TRUE)
Y.boostrap[,i] = Y[bootstramp.sample.indexes]
}
Y.boostrap
save.image("~/GitHub/Project/With Correct Ys.RData")
regress.func(Y,preds.in.order)
install.packages("tidyr")
library(tidyr)
library(table4)
data(table1); data(table2); data(table3); data(table4a); data(table4b)
## gathering
table4a
# We want to make t so that the year associated is there in the data
table4a %>%
gather('1999', '2000', key="year", value="cases")
library(dplyr)
tidy4a <- table4a %>%
gather(`1999`, `2000`, key = "year", value = "cases")
tidy4b <- table4b %>%
gather(`1999`, `2000`, key = "year", value = "population")
tidy4a
tidy4b
left_join(tidy4a, tidy4b)
table2
spread(table2, key = type, value = count)
table3
table3 %>%
separate(rate, into = c("cases", "population"))
table3 %>%
separate(rate, into = c("cases", "population"), sep = "/")
table3 %>%
separate(rate, into = c("cases", "population"), convert = TRUE)
getwd()
setwd("C:/Users/jgros/documents/GitHub/PS7")
getwd()
list.files()
data = read.csv("March2018.csv")
data
library(tidyr)
library(table4)
data("table4a")
table4a
?data
class(table4a)
data = as.tbl(read.csv("March2018.csv"))
data
library(dplyr)
library(nycflights13)
data(flights)
class(flights)
class(data)
library(dplyr)
library(ggplot2)
setwd("C:/Users/jgros/documents/GitHub/PS7")
getwd()
crime.data = as.tbl(read.csv("March2018.csv"))
select(crime.data)
select(crime.data,description)
colnames(crime.data)
select(crime.data,Description)
select(crime.data,Description)
select(flights, year)
## Getting set up
library(dplyr)
library(nycflights13)
## Arrange
arrange(flights, day)
arrange(flights, desc(day))
select(flights, year)
select(crime.data,Description)
?select
rm(list = ls())
## Getting set up
library(dplyr)
#install.packages("nycflights13")
library(nycflights13)
data(flights)
head(flights)
## Filter
justMay<-filter(flights, month==5)
head(justMay)
class(justMay)
## Arrange
arrange(flights, day)
arrange(flights, desc(day))
select(flights, year)
?select()
select(flights, year:day)
select(flights, -(year:day))
select(flights, starts_with("ye"))
j = read.csv("March2018.csv")
class(J)
class(j)
crime.data = tbl_df(read.csv("March2018.csv"))
# Import Libaries
library(dplyr)
library(ggplot2)
select(crime.data2)
select(crime.data,2)
select(crime.data)
class(crime.data)
select(flights, contains("ye"))
rename(flights, tail_num=tailnum)
## Arrange
arrange(flights, day)
arrange(flights, desc(day))
select(flights, year)
?select
detach("MASS",unload = TRUE)
detach("package:MASS",unload = TRUE)
detach("package:arm",unload = TRUE)
detach("package:MASS",unload = TRUE)
detach("package:lme4",unload = TRUE)
detach("package:MASS",unload = TRUE)
?select
